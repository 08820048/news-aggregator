---
title: "AI just leveled up and there are no guardrails anymore"
source: "Unknown"
url: "https://www.cnbc.com/2026/02/28/ai-selloff-politics-agents.html"
published: "2026-02-28T13:00:01.000Z"
category: "finance"
summary: "CNBC's Deirdre Bosa goes inside the AI-driven market meltdown, the political fight, and the race that's moving faster than anyone can govern."
---
In the first two months of 2026, generative [artificial intelligence](https://www.cnbc.com/ai-effect/) has undergone a rapid scaling of capabilities, going from chatbot to full-blown executive assistant and triggering an indiscriminate sell-off across sectors, hitting [software](https://www.cnbc.com/2026/02/27/tech-download-existential-software-crisis.html), legal, insurance and [cybersecurity](https://www.cnbc.com/2026/02/23/cybersecurity-stocks-are-latest-ai-victim-analysts-say-buy-the-dip.html) stocks.

"AI just went through its third inflection," [Nvidia](https://www.cnbc.com/quotes/NVDA/) CEO [Jensen Huang](https://www.cnbc.com/2026/02/26/nvidia-jensen-huang-gpu-ai-threat-software-companies-saas-earnings-chips.html) told CNBC's Becky Quick on Wednesday. "Now, with these agentic systems, we're having these agents able to reason, take tasks, and actually do work."

But the faster AI moves, the faster the safety nets are coming off.

[Anthropic](https://www.cnbc.com/2026/02/24/anthropic-openai-china-firms-distillation-deepseek.html) was just [blacklisted](https://www.cnbc.com/2026/02/27/trump-anthropic-ai-pentagon.html) by the Trump administration after the AI startup refused to comply with the Pentagon's demands about the use of its technology. Anthropic was founded on the promise of building AI responsibly, but scrapped its core safety pledge this week in the midst of the Pentagon battle, replacing hard commitments with [what it calls](https://www.anthropic.com/news/responsible-scaling-policy-v3) "nonbinding, publicly declared targets."

It said part of the reason was competitors racing ahead without the same guardrails. OpenAI is now running ads that CEO Sam Altman [once said](https://www.businessinsider.com/chatgpt-ads-openai-2026-1) the company would only monetize as a last resort.

Researchers at both companies have resigned in recent weeks, warning of the risks.

The tension around AI safety has the potential to be a pivotal issue in the 2026 midterms, and [one race](https://www.politico.com/news/2026/02/09/the-ny-congressional-race-on-the-frontlines-of-an-ai-industry-civil-war-00772238) is already signaling how it might shake out.

New York State Assemblyman Alex Bores authored the first major AI safety law in the country and is now running for Congress. And he's become a target for the camp that's arguing for looser regulations.

Bores is now facing a [$125 million super PAC](https://www.cnbc.com/2026/01/30/ai-industry-super-pac-raises-campaign-money.html) that counts OpenAI cofounder Greg Brockman, Andreessen Horowitz and [Palantir](https://www.cnbc.com/quotes/PLTR/)'s Joe Lonsdale as backers.

"They've made clear they want to make an example here, that if they win this race, they're going to go to every member of Congress and say, don't you dare regulate AI, otherwise we'll spend $10 million against you," Bores said. "This is moving very, very quickly. I still think there's a lot of great steps that we can and should take right now, but absolutely, we are running out of time."

[Watch this video](https://www.cnbc.com/video/2026/02/28/ai-is-taking-over-and-there-are-no-guardrails.html) to learn more.
