---
title: "In puzzling outbreak, officials look to cold beer, gross ice, and ChatGPT"
source: "
                    Beth Mole
                "
url: "https://arstechnica.com/health/2026/02/did-chatgpt-help-health-officials-solve-a-weird-outbreak-maybe/"
published: "2026-02-28T18:17:12.000Z"
category: "tech"
summary: "An AI chatbot convinced health investigators they had the right answer."
---
## An AI assist?

The author of the MMWR report, county health official Katherine Houser, noted that the beer-tent workers were hesitant to give details because they didn’t want to get any of their community members in trouble. But one let slip that someone had put leftover food in the cooler overnight at the start of the fair.

The county health officials hypothesized that the cooler had become contaminated with _Salmonella_ that spread to beer cans from which people then drank, allowing for infection. But with the makeshift cooler gone, it would remain only a hypothesis. So, the health investigators then turned to ChatGPT for assurances.

After providing the chatbot with details of the outbreak, health investigators asked it several questions, including: “Will _S._ Agbeni grow in an improperly drained cooler?”; “Are any other sources, other than ice, likely if only canned beverages and no foods were available at this location?’ ; and “What examples of similar outbreaks have been documented in scientific literature?”

Some of the questions are easy enough to answer without a chatbot. [A simple search](https://pubmed.ncbi.nlm.nih.gov/?term=%22salmonella%22+AND+%22ice%22) on PubMed, a federal database of scientific literature, quickly pulls up examples of _Salmonella_ being found in ice, for example. But, the chatbot assured the officials that the cooler was a “credible and likely” source of the outbreak and they stuck with the hypothesis.

In the end, the officials required new cooler sanitation protocols—and concluded that the AI assistance was helpful. “AI was effective in this rural setting for rapid situational awareness,” Houser wrote. However, she also acknowledged the potential concerns of using AI for outbreak investigations: “Given the inherent limitations of generative AI tools, including potential inaccuracies and lack of source transparency, all AI-generated summaries were critically reviewed and validated against primary literature before incorporation,” she wrote.

Overall, the case report has a murky ending. It’s unclear how helpful the chatbot actually was in this case. Critically reviewing AI-generated answers can easily take as much time as simply researching the answer on one’s own. And of course, we’ll never know for certain what was really going on in that makeshift beer cooler—though the new cooler sanitation protocols seem like a good idea, regardless.
