---
title: "America desperately needs new privacy laws"
source: "Adi Robertson"
url: "https://www.theverge.com/column/882516/privacy-laws-america"
published: "2026-02-22T13:00:00.000Z"
category: "tech"
summary: "This is The Stepback, a weekly newsletter breaking down one essential story from the tech world. For more on the dire state of tech regulation, follow Adi Robertson. The Stepback arrives in our subscribers' inboxes at 8AM ET. Opt in for The Stepback here. How it started In 1973, long before the modern digital era, the US Department of Health, Education, and Welfare (HEW) published a report called \"Records, Computers, and the Rights of Citizens.\" Networked computers seemed \"destined to become the principal medium for making, storing, and using records about people,\" the report's foreword began. These systems could be a \"powerful management … Read the full story at The Verge."
---
_This is_ [The Stepback](https://www.theverge.com/the-stepback-newsletter)_, a weekly newsletter breaking down one essential story from the tech world. For more on the dire state of tech regulation, [follow Adi Robertson](https://www.theverge.com/authors/adi-robertson)._ The Stepback _arrives in our subscribers’ inboxes at 8AM ET. Opt in for_ The Stepback _[_here_](https://www.theverge.com/newsletters)._

## How it started

In 1973, long before the modern digital era, the US Department of Health, Education, and Welfare (HEW) published a report called “Records, Computers, and the Rights of Citizens.” Networked computers seemed “destined to become the principal medium for making, storing, and using records about people,” [the report’s foreword began](https://www.justice.gov/opcl/docs/rec-com-rights.pdf). These systems could be a “powerful management tool.” But with few legal safeguards, they could erode the basic human right to privacy — particularly “control by an individual over the uses made of information about him.”

These concerns weren’t just cheap talk in Washington. In 1974, Congress passed the Privacy Act, which set some of the first rules aimed at computerized records systems — limiting when government agencies could share information and outlining what access individuals should have. Over the course of the 20th century, the Privacy Act was joined by more privacy rules for fields including [healthcare](https://en.wikipedia.org/wiki/Health_Insurance_Portability_and_Accountability_Act), [websites for children](https://en.wikipedia.org/wiki/Children%27s_Online_Privacy_Protection_Act), [electronic communications](https://en.wikipedia.org/wiki/Electronic_Communications_Privacy_Act), and even [video cassette rentals](https://en.wikipedia.org/wiki/Video_Privacy_Protection_Act). But over the past couple of decades, amid an explosion in digital surveillance by governments and private companies, Congress has repeatedly failed to keep up.

Lawmakers have weighed numerous plans for preserving Americans’ privacy, yet over and over, they’ve fizzled. Attempts to rein in government spying — like [proposed updates to the Electronic Communications Privacy Act of 1986](https://www.theverge.com/policy/2012/8/10/3226111/ecpa-time-to-reformat-data-privacy-for-the-21st-century) — have been sandbagged by fears they’d compromise police and anti-terrorism operations. Despite [multiple](https://www.theverge.com/2021/5/20/22444515/amy-klobuchar-data-privacy-protection-facebook-state-laws) [concerted](https://www.theverge.com/2022/6/14/23167705/data-privacy-legislation-bill-compromise-energy-commerce-cantwell-pallone) [attempts](https://www.theverge.com/2024/4/8/24124143/lawmakers-unveil-bipartisan-comprehensive-digital-american-privacy-rights-act-bill) from members of both parties, Congress hasn’t passed a bill that governs how private companies collect data and what rights people have over their own information. Even highly targeted proposals like [the Fourth Amendment Is Not for Sale Act](https://www.theverge.com/2021/4/21/22395650/wyden-paul-fourth-amendment-is-not-for-sale-act-privacy-data-brokers-clearview-ai) — which restricts police from bypassing existing privacy laws by using data brokers — haven’t cleared the hurdle of becoming law.

Meanwhile, new technologies, from augmented reality glasses to generative artificial intelligence, create fresh risks every day — making it easier than ever to [surreptitiously surveil people](https://www.404media.co/a-cbp-agent-wore-meta-smart-glasses-to-an-immigration-raid-in-los-angeles/) or encouraging sharing [intimate information](https://www.theverge.com/policy/665685/ai-therapy-meta-chatbot-surveillance-risks-trump) with tech platforms.

## How it’s going

Immigration agents are [harassing citizens](https://www.nytimes.com/2026/01/30/technology/tech-ice-facial-recognition-palantir.html) that they’ve identified with data analytics tools and facial recognition. Data breaches at major tech companies are common, and security regulations [meant to prevent them](https://www.theverge.com/policy/824508/fcc-telecom-salt-typhoon-hack) are being rolled back. Amazon just aired a Super Bowl ad bragging about how your doorbell can become part of a [distributed surveillance dragnet](https://www.theverge.com/news/881339/after-search-party-backlash-ring-is-still-avoiding-the-bigger-questions) for finding dogs.

At every point, invasions of privacy don’t just risk revealing something intimate about you to the world, they shift the balance of power toward whoever holds the most data. Take algorithmic pricing, where companies use personal information about shoppers to set individualized prices they estimate people will pay — resulting in companies like Instacart charging users [different prices for the same item](https://www.consumerreports.org/money/questionable-business-practices/instacart-stops-ai-pricing-experiments-a1176475852/). (The company said this was an experiment it’s since ended.)

State-level and international regulations have addressed some privacy risks. Companies in Europe have been governed by the General Data Protection Regulation (GDPR) [since 2018](https://www.theverge.com/2018/3/28/17172548/gdpr-compliance-requirements-privacy-notice), though a rollback was proposed [late last year](https://www.theverge.com/news/823750/european-union-ai-act-gdpr-changes). Several states have passed some form of general privacy framework, as well as more specific rules — [Illinois’ biometric privacy law](https://www.theverge.com/2019/1/26/18197567/six-flags-illinois-biometric-information-privacy-act-facial-recognition) has facilitated lawsuits against Meta and others, for instance, and New York [mandated algorithmic pricing disclosure](https://www.governor.ny.gov/news/protecting-new-yorkers-secret-online-price-hikes-governor-hochul-announces-nation-leading) a few months ago. However, privacy advocates warn many of the rules are inadequate. The Electronic Privacy Information Center (EPIC) and US PIRG Education Fund [graded state consumer privacy bills](https://pirg.org/edfund/resources/state-privacy-laws/) in 2025, and only two states, California and Maryland, earned higher than a C.

EPIC deputy director Caitriona Fitzgerald tells _The Verge_ that Congress _has_ passed at least one meaningful reform lately: the 2024 Protecting Americans’ Data from Foreign Adversaries Act, which Fitzgerald calls “the strongest privacy law to be passed at the federal level in recent years.” PADFAA bars data brokers from letting hostile nations access sensitive personal information of Americans, and EPIC [used it to file a complaint](https://epic.org/google-and-ceo-sundar-pichai-under-fire-for-sending-americans-data-to-foreign-adversaries-in-new-national-security-complaint/) against Google’s real-time bidding ads system — which it alleges broadcast sensitive data indiscriminately.

Overall, though, it’s fair to say the situation isn’t great.

## What happens next

As of early 2026, in many places, a sense of learned helplessness around privacy has taken hold. [Companies like Meta push the line](https://www.404media.co/whats-the-difference-between-ai-glasses-and-an-iphone-a-helpful-guide-for-meta-pr/) that if an existing technology already poses privacy concerns, it’s unreasonable to complain that a new technology does it even worse. [According to internal documents](https://www.nytimes.com/2026/02/13/technology/meta-facial-recognition-smart-glasses.html), Meta also apparently believes that the Trump administration’s highly public flouting of civil liberties (or what Meta euphemistically deems a “dynamic political environment”) will keep activists distracted, leaving it free to push invasive features like facial recognition into products.

But the administration’s actions are making the dangers of these systems more and more difficult to ignore. It’s one thing to know the government _could_ look up personal information about you. It’s another to have [ICE agents intimidate you](https://www.nytimes.com/2026/01/30/technology/tech-ice-facial-recognition-palantir.html) by dropping your name.

Not all of today’s privacy nightmares have easy regulatory solutions. But privacy groups have said for years that there are obvious ways to start improving the situation. [A long-standing wishlist from a coalition](https://epic.org/wp-content/uploads/2022/01/Privacy-and-Digital-Rights-For-All-Framework.pdf) that includes EPIC, PIRG, and others suggests creating a new independent federal Data Protection Agency, as well as a private right of action that would let individuals sue over violations of privacy laws. One of the most recent proposals is [the Data Justice Act](https://www.law.nyu.edu/documents/data-justice-act), a piece of model legislation outlined last month by a group of scholars at NYU Law. It’s aimed at limiting state collection and use of our deep digital footprints, aiming to redefine personal data “not as information the state may freely access, but as something inherently ours.”

There’s likely no turning back the clock on many digital technologies — nor, in many cases, would people want to. But it’s past time for more lawmakers to take the risks these technologies create seriously and decide it’s worth fighting back.

## By the way

-   In many ways, governments across the world are actually going backward on privacy, thanks to [the rise of online age-gating](https://www.theverge.com/analysis/715767/online-age-verification-not-ready). In the US, the Supreme Court has already okayed age verification for sites with a large volume of adult content. Now, multiple states have passed laws that require it for essentially every app on your phone, a policy the Supreme Court seems likely to consider sometime this year.
-   Virtually every problem in tech regulation is intertwined, so tech monopolies _also_ exacerbate privacy problems by reducing competition and concentrating information in a few places where it can be exploited. (That’s another issue Congress has taken up but [failed to follow through on](https://www.theverge.com/2022/12/20/23517807/big-tech-antitrust-bills-congress-omnibus).) Also, laws don’t work if the government won’t fairly enforce them, so the Trump administration’s era of [gangster tech regulation](https://www.theverge.com/2025/1/20/24346317/trump-gangster-tech-regulation-corruption-grift) needs to end.
-   One of the simplest rallying cries for privacy in recent years is “[ban facial recognition](https://www.banfacialrecognition.com/)” — typically from use by government and law enforcement, but there’s a [push to limit](https://epic.org/epic-urges-ftc-states-to-block-metas-facial-recognition-smart-glasses-plan/) its rollout privately on smart glasses, too.

## Read this

**Follow topics and authors** from this story to see more like this in your personalized homepage feed and to receive email updates.

-   Adi Robertson
