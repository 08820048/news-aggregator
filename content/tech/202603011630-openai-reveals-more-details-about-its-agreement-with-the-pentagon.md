---
title: "OpenAI reveals more details about its agreement with the Pentagon"
source: "Anthony Ha"
url: "https://techcrunch.com/2026/03/01/openai-shares-more-details-about-its-agreement-with-the-pentagon/"
published: "2026-03-01T16:30:10.000Z"
category: "tech"
summary: "By CEO Sam Altman’s own admission, OpenAI’s deal with the Department of Defense was “definitely rushed,” and “the optics don’t look good.”"
---
By CEO Sam Altman’s own admission, OpenAI’s deal with the Department of Defense was “definitely rushed,” and “the optics don’t look good.”

After [negotiations between Anthropic and the Pentagon fell through](https://techcrunch.com/2026/02/27/pentagon-moves-to-designate-anthropic-as-a-supply-chain-risk/) on Friday, President Donald Trump directed federal agencies to stop using Anthropic’s technology after [a six-month transition period](https://www.wsj.com/livecoverage/iran-strikes-2026/card/u-s-strikes-in-middle-east-use-anthropic-hours-after-trump-ban-ozNO0iClZpfpL7K7ElJ2), and Secretary of Defense Pete Hegseth said he was designating the AI company as a supply-chain risk.

Then, [OpenAI quickly announced](https://techcrunch.com/2026/02/28/openais-sam-altman-announces-pentagon-deal-with-technical-safeguards/) that it had reached a deal of its own for models to be deployed in classified environments. With Anthropic saying it was drawing red lines around the use of its technology in fully autonomous weapons or mass domestic surveillance, and Altman saying OpenAI had the same red lines, there were some obvious questions: Was OpenAI being honest about its safeguards? Why was it able to reach a deal while Anthropic was not?

So as OpenAI executives defended the agreement on social media, the company also published [a blog post outlining its approach](https://openai.com/index/our-agreement-with-the-department-of-war/).

In fact, the post pointed to three areas where it said OpenAI’s models cannot be used — mass domestic surveillance, autonomous weapon systems, and “high-stakes automated decisions (e.g. systems such as ‘social credit’).”

The company said that in contrast to other AI companies that have “reduced or removed their safety guardrails and relied primarily on usage policies as their primary safeguards in national security deployments,” OpenAI’s agreement protects its red lines “through a more expansive, multi-layered approach.”

“We retain full discretion over our safety stack, we deploy via cloud, cleared OpenAI personnel are in the loop, and we have strong contractual protections,” the blog said. “This is all in addition to the strong existing protections in U.S. law.”

Techcrunch event

San Francisco, CA | October 13-15, 2026

The company added, “We don’t know why Anthropic could not reach this deal, and we hope that they and more labs will consider it.”

After the post was published, [Techdirt’s Mike Masnick claimed](https://bsky.app/profile/masnick.com/post/3mfxyktqgyp24) that the deal “absolutely does allow for domestic surveillance,” because it says the collection of private data will comply with [Executive Order 12333](https://www.washingtonpost.com/opinions/meet-executive-order-12333-the-reagan-rule-that-lets-the-nsa-spy-on-americans/2014/07/18/93d2ac22-0b93-11e4-b8e5-d0de80767fc2_story.html) (along with a number of other laws). Masnick described that order as “how the NSA hides its domestic surveillance by capturing communications by tapping into lines \*outside the US\* even if it contains info from/on US persons.”

In [a LinkedIn post](https://www.linkedin.com/posts/katrinaemmons_our-agreement-with-the-department-of-war-activity-7433627924815163392-hMRw/), OpenAI’s head of national security partnerships Katrina Mulligan argued that much of the discussion around the contract language assumes “the only thing standing between Americans and the use of AI for mass domestic surveillance and autonomous weapons is a single usage policy provision in a single contract with the Department of War.”

“That’s not how any of this works,” Mulligan said, adding, “Deployment architecture matters more than contract language \[…\] By limiting our deployment to cloud API, we can ensure that our models cannot be integrated directly into weapons systems, sensors, or other operational hardware.”

Altman also fielded questions about the deal on X, where he [admitted it had been rushed](https://x.com/sama/status/2027911640256286973) and resulted in significant backlash against OpenAI (to the extent that [Anthropic’s Claude overtook OpenAI’s ChatGPT in Apple’s App Store](https://techcrunch.com/2026/03/01/anthropics-claude-rises-to-no-2-in-the-app-store-following-pentagon-dispute/) on Saturday). So why do it?

“We really wanted to de-escalate things, and we thought the deal on offer was good,” Altman said. “If we are right and this does lead to a de-escalation between the DoW and the industry, we will look like geniuses, and a company that took on a lot of pain to do things to help the industry. If not, we will continue to be characterized as \[…\] rushed and uncareful.”

Anthony Ha is TechCrunch’s weekend editor. Previously, he worked as a tech reporter at Adweek, a senior editor at VentureBeat, a local government reporter at the Hollister Free Lance, and vice president of content at a VC firm. He lives in New York City.

You can contact or verify outreach from Anthony by emailing [anthony.ha@techcrunch.com](mailto:anthony.ha@techcrunch.com).

[View Bio](https://techcrunch.com/author/anthony-ha/)
