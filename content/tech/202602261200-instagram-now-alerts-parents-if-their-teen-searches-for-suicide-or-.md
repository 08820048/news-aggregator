---
title: "Instagram now alerts parents if their teen searches for suicide or self-harm content"
source: "Aisha Malik"
url: "https://techcrunch.com/2026/02/26/instagram-now-alerts-parents-if-their-teen-searches-for-suicide-or-self-harm-content/"
published: "2026-02-26T12:00:00.000Z"
category: "tech"
summary: "Parents will be informed if their teen searches for suicide or self-harm content and offered resources."
---
Instagram will start alerting parents if their teen repeatedly tries to search for terms related to suicide or self-harm within a short period of time, the company [announced](https://about.fb.com/news/2026/02/new-meta-alerts-let-parents-know-if-teen-may-need-support) on Thursday. The alerts are launching in the coming weeks to parents who are enrolled in parental supervision on Instagram.

The Meta-owned social platform says that while it already blocks users from searching for suicide and self-harm content, these new alerts are designed to make sure parents are aware if their teen is repeatedly trying to search for this content so that they can support their teen.

Searches that may trigger an alert include phrases encouraging suicide or self-harm, phrases indicating a teen might be at risk of harming themselves, and terms such as “suicide” or “self-harm.”

Instagram says parents will receive the alert via email, text, or WhatsApp, depending on the contact information they’ve provided, along with an in-app notification. The notification will include resources designed to help parents approach conversations with their teen.

![](https://techcrunch.com/wp-content/uploads/2026/02/Parent-Alert-and-Tips.png?w=680)

**Image Credits:**Instagram

The move comes as Meta and other big tech companies are currently facing [several lawsuits](https://www.npr.org/2026/02/18/nx-s1-5716229/zuckerberg-social-media-addiction-trial) looking to hold social media giants accountable for harming teens.

During testimony for a lawsuit taking place in the U.S. District Court in the Northern District of California this week, Instagram head Adam Mosseri was [grilled by prosecutors](https://techcrunch.com/2026/02/24/instagram-head-pressed-on-lengthy-delay-to-launch-teen-safety-features-like-a-nudity-filter-court-filing-reveals/) in an ongoing social media addiction case over the app’s delayed rollout of basic safety features, including a nudity filter for private messages to teens.

Additionally, during testimony in a separate lawsuit before the Los Angeles County Superior Court, it was revealed that an internal research study at Meta found that parental supervision and controls [had little impact on kids’ compulsive](https://techcrunch.com/2026/02/17/metas-own-research-found-parental-supervision-doesnt-really-help-curb-teens-compulsive-social-media-use/) use of social media. The study also found that children who faced stressful life events were more likely to struggle with regulating their social media use appropriately.

Given the ongoing lawsuits accusing the company of failing to protect teens on its platforms, the timing of these new alerts isn’t exactly surprising.

The company notes that it will aim to avoid sending these notifications unnecessarily, as overuse could reduce their overall effectiveness.

“In working to strike this important balance, we analyzed Instagram search behavior and consulted with experts from our Suicide and Self-Harm Advisory Group,” Instagram explained in a blog post. “We chose a threshold that requires a few searches within a short period of time, while still erring on the side of caution. While that means we may sometimes notify parents when there may not be a real cause for concern, we feel — and experts agree — that this is the right starting point, and we’ll continue to monitor and listen to feedback to make sure we’re in the right place.”

The alerts are rolling out in the U.S., U.K., Australia, and Canada next week, and will become available in other regions later this year.

In the future, Instagram plans to launch these notifications when a teen tries to engage the app’s AI in conversations about suicide or self-harm.

Aisha is a consumer news reporter at TechCrunch. Prior to joining the publication in 2021, she was a telecom reporter at MobileSyrup. Aisha holds an honours bachelor’s degree from University of Toronto and a master’s degree in journalism from Western University.

You can contact or verify outreach from Aisha by emailing [aisha@techcrunch.com](mailto:aisha@techcrunch.com) or via encrypted message at aisha\_malik.01 on Signal.

[View Bio](https://techcrunch.com/author/aisha-malik/)
