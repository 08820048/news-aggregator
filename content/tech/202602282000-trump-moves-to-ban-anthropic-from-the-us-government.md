---
title: "Trump moves to ban Anthropic from the US government"
source: "
                    Will Knight, WIRED.com
                "
url: "https://arstechnica.com/tech-policy/2026/02/trump-moves-to-ban-anthropic-from-the-us-government/"
published: "2026-02-28T20:00:26.000Z"
category: "tech"
summary: "The Defense Department pressured Anthropic to drop restrictions on how its AI can be used by the military."
---
[Skip to content](#main)

theoretical use cases

The Defense Department pressured Anthropic to drop restrictions on how its AI can be used by the military.

Anthropic CEO Dario Amodei on Tuesday, July 25, 2023, during a hearing on AI held by the Senate Judiciary Subcommittee on Privacy, Technology, and the Law. Credit: Getty Images | Bloomberg

US President Donald Trump [announced](https://truthsocial.com/@realDonaldTrump/posts/116144552969293195) Friday that he was instructing every federal agency to “immediately cease” use of Anthropic’s AI tools. The move comes after [Anthropic](https://www.wired.com/tag/anthropic/) and top officials clashed for weeks over military applications of artificial intelligence.

“The Leftwing nut jobs at Anthropic have made a DISASTROUS MISTAKE trying to STRONG-ARM the Department of War,” Trump said in a post on [Truth Social](https://truthsocial.com/@realDonaldTrump/116144552969293195).

Trump said that there would be a “six month phase out period” for agencies using Anthropic, which could allow time for further negotiations between the government and the AI startup.

The Pentagon and Anthropic did not immediately respond to requests for comment.

The [Department of Defense](https://www.wired.com/story/department-of-defense-department-of-war/) has sought to change the terms of a deal struck with Anthropic and other companies last July to eliminate restrictions on how AI can be deployed and instead permit “all lawful use” of the technology. Anthropic objected to the change, claiming that it could allow AI to be used to fully control lethal autonomous weapons or to conduct mass surveillance on US citizens.

The Pentagon does not currently use AI in these ways, and has said it has no plans to do so. However, top Trump administration officials have voiced opposition to the idea of a civilian tech company dictating military use of such an important technology.

Anthropic was the first major AI lab to work with the US military, through a [$200 million deal](https://www.anthropic.com/news/anthropic-and-the-department-of-defense-to-advance-responsible-ai-in-defense-operations) signed with the Pentagon last year. It created several custom models known as Claude Gov that have fewer restrictions than its regular ones. Google, OpenAI, and xAI signed similar deals around the same time, but Anthropic is the only AI company currently working with classified systems.

Anthropic’s model is available through platforms provided by Palantir and Amazon’s cloud platform for classified military work. Claude Gov is currently largely used for run-of-the-mill tasks, like writing reports and summarizing documents, but it is also used for intelligence analysis and military planning, according to one source familiar with the situation who spoke to WIRED on condition of anonymity because they are not authorized to discuss the matter publicly.

In recent years, Silicon Valley has gone from largely avoiding defense work to increasingly embracing it and eventually becoming full-blown military contractors. The fight between Anthropic and the Pentagon is now testing the limits of that shift. This week, several hundred workers from OpenAI and Google signed [an open letter](https://notdivided.org/) supporting Anthropic and criticizing their own companies’ decisions to remove restrictions on military use of AI.

In a memo sent to OpenAI staff today, CEO Sam Altman said that the company agreed with Anthropic and also viewed mass surveillance and fully autonomous weapons as a “red line.” Altman added that the company would try to agree to a deal with the Pentagon that would let it continue working with the military, The Wall Street Journal [reported](https://www.wsj.com/tech/ai/openais-sam-altman-calls-for-de-escalation-in-anthropic-showdown-with-hegseth-03ecbac8?mod=hp_lead_pos1).

The public spat between the Pentagon and Anthropic began after [Axios reported](https://www.axios.com/2026/02/13/anthropic-claude-maduro-raid-pentagon) that US military leaders used Claude to assist in planning its operation to capture Venezuela’s president, [Nicolás Maduro](https://www.wired.com/story/us-invaded-venezuela-and-captured-nicolas-maduro-chatgpt-disagrees/). After the operation, an employee at Palantir relayed concerns from an Anthropic staffer to US military leaders about how its models had been used. Anthropic has denied ever raising concerns or interfering with the Pentagon’s use of its technology.

The dispute between Anthropic and the Department of Defense has escalated in recent days, with officials publicly trading barbs with the AI company on social media.

Defense Secretary Pete Hegseth met with Anthropic’s CEO, Dario Amodei, earlier this week. He gave the company until Friday to commit to changing the terms of its contract to allow “all lawful use” of its models. Hegseth praised Anthropic’s products during the meeting and said that the Department of Defense wanted to continue working with Anthropic, according to one source familiar with interaction who was not authorized to discuss it publicly.

Some experts say that the dispute boils down to a clash over vibes rather than concrete disagreements over how artificial intelligence should be deployed. “This is such an unnecessary dispute in my opinion,” says Michael Horowitz, an expert on military use of AI and former Deputy Assistant Secretary for emerging technologies at the Pentagon. “It is about theoretical use cases that are not on the table for now.”

Horowitz notes that Anthropic has supported all of the ways the Department of Defense has proposed using its technology thus far. “My sense is that the Pentagon and Anthropic agree at present about the use cases where the technology is not ready for prime time,” he adds.

Anthropic was founded on the idea that AI should be built with safety at its core. In January, Amoedi penned [a blog post](https://www.darioamodei.com/essay/the-adolescence-of-technology) about the risks of powerful artificial intelligence that touched upon the dangers of fully autonomous AI-controlled weapons.

“These weapons also have legitimate uses in the defense of democracy,” Amodei wrote. “But they are a dangerous weapon to wield.”

_Additional reporting by Paresh Dave._

_This story originally appeared at [WIRED.com](https://www.wired.com/story/trump-moves-to-ban-anthropic-from-the-us-government/)_

[![Photo of WIRED](https://cdn.arstechnica.net/wp-content/uploads/2023/09/wired-headshot.jpg)](https://arstechnica.com/author/wired-com/)

Wired.com is your essential daily guide to what's next, delivering the most original and complete take you'll find anywhere on innovation's impact on technology, science, business and culture.

[70 Comments](https://arstechnica.com/tech-policy/2026/02/trump-moves-to-ban-anthropic-from-the-us-government/#comments "70 comments")

1.  [![Listing image for first story in Most Read: Google quantum-proofs HTTPS by squeezing 15kB of data into 700-byte space](https://cdn.arstechnica.net/wp-content/uploads/2025/06/https-768x432.jpg)](https://arstechnica.com/security/2026/02/google-is-using-clever-math-to-quantum-proof-https-certificates/)
