---
title: "Musk bashes OpenAI in deposition, saying ‘nobody committed suicide because of Grok’"
source: "Sarah Perez"
url: "https://techcrunch.com/2026/02/27/musk-bashes-openai-in-deposition-saying-nobody-committed-suicide-because-of-grok/"
published: "2026-02-27T19:42:00.000Z"
category: "tech"
summary: "In his lawsuit against OpenAI, Musk touted xAI safety compared with ChatGPT. A few months later, xAI's Grok flooded X with nonconsensual nude images."
---
In a newly released deposition filed in Elon Musk’s case against OpenAI, the tech executive attacked OpenAI’s safety record, claiming that his company, xAI, better prioritizes safety. He went so far as to say that “Nobody has committed suicide because of Grok, but apparently they have because of ChatGPT.”

The comment came up in a line of questioning about a [public letter](https://techcrunch.com/2023/03/28/1100-notable-signatories-just-signed-an-open-letter-asking-all-ai-labs-to-immediately-pause-for-at-least-6-months/) Musk signed in March 2023. In it, he called on AI labs to pause development of AI systems more powerful than GPT-4, OpenAI’s flagship model at the time, for at least six months. The letter, which was signed by over 1,100 people, including many AI experts, stated there was not enough planning and management taking place at AI labs, as they were locked in an “out-of-control race to develop and deploy ever more powerful digital minds that no one — not even their creators — can understand, predict, or reliably control.”

Those fears have since gained credibility. OpenAI now faces a [series of lawsuits](https://socialmediavictims.org/press-releases/smvlc-tech-justice-law-project-lawsuits-accuse-chatgpt-of-emotional-manipulation-supercharging-ai-delusions-and-acting-as-a-suicide-coach/) alleging that [ChatGPT’s manipulative conversation tactics](https://techcrunch.com/2025/11/23/chatgpt-told-them-they-were-special-their-families-say-it-led-to-tragedy/) have led several people to experience negative mental health effects, with some dying by suicide. Musk’s comment suggests that these incidents could be used as fodder in his case against OpenAI.

The transcript of Musk’s video testimony, which took place back in September, was filed publicly this week, ahead of the expected jury trial next month.

The [lawsuit](https://techcrunch.com/2024/03/01/elon-musk-openai-sam-altman-court/) against OpenAI centers on the company’s shift from a nonprofit AI research lab to a for-profit company, which [Musk claims violated](https://techcrunch.com/2026/01/08/elon-musks-lawsuit-against-openai-will-face-a-jury-in-march/) its founding agreements. As part of his arguments, Musk claims that AI safety could be compromised by OpenAI’s commercial relationships, as such relationships would place speed, scale, and revenue above safety concerns.

However, since that recording, xAI has faced safety concerns of its own. Last month, Musk’s social network X was [flooded with nonconsensual nude images](https://techcrunch.com/2026/01/08/governments-grapple-with-the-flood-of-non-consensual-nudity-on-x/) generated by xAI’s Grok, some of which [were said to be of minors](https://techcrunch.com/2026/01/14/musk-denies-awareness-of-grok-sexual-underage-images-as-california-ag-launches-probe/). This led the California Attorney General’s office to [open an investigation](https://oag.ca.gov/news/press-releases/attorney-general-bonta-launches-investigation-xai-grok-over-undressed-sexual-ai) into the matter. The EU is also [running its own investigation](https://www.pbs.org/newshour/world/musks-grok-chatbot-faces-eu-privacy-investigation-over-sexualized-deepfake-images), and other governments have taken action, too, with some imposing blocks and bans.

In the newly filed deposition, Musk claimed he had signed the AI safety letter because “it seemed like a good idea,” not because he had just incorporated an AI company looking to compete with OpenAI.

“I signed it, as many people did, to urge caution with AI development,” Musk said. “I just wanted … AI safety to be prioritized.”

![](https://techcrunch.com/wp-content/uploads/2026/02/sure-jan-elon.jpg?w=500)

**Image Credits:**imgflip

Musk also responded to other questions in the deposition, including those about artificial general intelligence, or AGI — the concept of AI that can match or surpass human reasoning across a broad range of tasks — saying “it has a risk.” He also confirmed that he “was mistaken” about his [supposed $100 million donation](https://techcrunch.com/2023/05/17/elon-musk-used-to-say-he-put-100m-in-openai-but-now-its-50m-here-are-the-receipts/) to OpenAI; the [second amended complaint](https://www.courtlistener.com/docket/69013420/170/musk-v-altman/) in the case puts the actual figure closer to $44.8 million.

He also recalled why OpenAI was founded, which, from his perspective, was because he was “increasingly concerned about the danger of Google being a monopoly in AI,” adding that his conversations with Google co-founder Larry Page were “alarming, in that he did not seem to be taking AI safety seriously.” OpenAI was formed as a counterweight to that threat, Musk claimed.

Sarah has worked as a reporter for TechCrunch since August 2011. She joined the company after having previously spent over three years at ReadWriteWeb. Prior to her work as a reporter, Sarah worked in I.T. across a number of industries, including banking, retail and software.

You can contact or verify outreach from Sarah by emailing [sarahp@techcrunch.com](mailto:sarahp@techcrunch.com) or via encrypted message at sarahperez.01 on Signal.

[View Bio](https://techcrunch.com/author/sarah-perez/)
