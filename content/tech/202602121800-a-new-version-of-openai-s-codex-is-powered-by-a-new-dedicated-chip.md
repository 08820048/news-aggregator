---
title: "A new version of OpenAI’s Codex is powered by a new dedicated chip"
source: "Lucas Ropek"
url: "https://techcrunch.com/2026/02/12/a-new-version-of-openais-codex-is-powered-by-a-new-dedicated-chip/"
published: "2026-02-12T18:00:00.000Z"
category: "tech"
summary: "OpenAI calls the new coding tool the \"first milestone\" in its relationship with the chipmaker."
---
On Thursday, OpenAI announced the release of a light-weight version of its agentic coding tool Codex, the latest model of which [OpenAI launched](https://techcrunch.com/2026/02/05/openai-launches-new-agentic-coding-model-only-minutes-after-anthropic-drops-its-own/) earlier this month. GPT-5.3-Codex-Spark is described by the company as a “smaller version” of that model, one that is designed for faster inference. To power that inference, OpenAI has brought in a dedicated chip from its hardware partner Cerebras, marking a new level of integration in the company’s physical infrastructure.

The [partnership](https://openai.com/index/cerebras-partnership/) between Cerebras and OpenAI was announced last month, when OpenAI [said that](https://techcrunch.com/2026/01/14/openai-signs-deal-reportedly-worth-10-billion-for-compute-from-cerebras/) it had reached a multi-year agreement with the firm worth over $10 billion. “Integrating Cerebras into our mix of compute solutions is all about making our AI respond much faster,” the company said at the time. Now, OpenAI calls Spark the “first milestone” in that relationship.

Spark, which OpenAI says is designed for swift, real-time collaboration and “rapid iteration,” will be powered by Cerebras’ Wafer Scale Engine 3. The WSE-3 is Cerebras’ [third-generation](https://spectrum.ieee.org/cerebras-chip-cs3) waferscale megachip, decked out with 4 trillion transistors. OpenAI describes the new lightweight tool as a “daily productivity driver, helping users with rapid prototyping” rather than the longer, heavier tasks that the original 5.3 is designed for. Spark is currently enjoying a research preview for ChatGPT Pro users in the Codex app.

In a tweet in advance of the announcement, CEO Sam Altman seemed to hint at the new model. “We have a special thing launching to Codex users on the Pro plan later today,” Altman tweeted. “It sparks joy for me.”

In its official statement, OpenAI emphasized Spark as designed for the lowest possible latency on Codex. “Codex-Spark is the first step toward a Codex that works in two complementary modes: real-time collaboration when you want rapid iteration, and long-running tasks when you need deeper reasoning and execution,” OpenAI shared. The company added that Cerebras’ chips excel at assisting “workflows that demand extremely low latency.”

Cerebras has been around [for over a decade](https://www.cerebras.ai/company) but, in the AI era, it has enjoyed an increasingly prominent role in the tech industry. Just last week, the company [announced that](https://techcrunch.com/2026/02/06/benchmark-raises-225m-in-special-funds-to-double-down-on-cerebras/) it had raised $1 billion in fresh capital at a valuation of [$23 billion](https://www.cerebras.ai/press-release/cerebras-systems-raises-usd1-billion-series-h). The company has [previously announced](https://www.cnbc.com/2025/05/15/cerebras-ceo-says-chipmakers-aspiration-is-to-hold-ipo-in-2025.html) its intentions to pursue an IPO.

“What excites us most about GPT-5.3-Codex-Spark is partnering with OpenAI and the developer community to discover what fast inference makes possible — new interaction patterns, new use cases, and a fundamentally different model experience,” Sean Lie, CTO and Co-Founder of Cerebras, said in a statement. “This preview is just the beginning.”

Techcrunch event

Boston, MA | June 23, 2026

Lucas is a senior writer at TechCrunch, where he covers artificial intelligence, consumer tech, and startups. He previously covered AI and cybersecurity at Gizmodo. You can contact Lucas by emailing lucas.ropek@techcrunch.com.

[View Bio](https://techcrunch.com/author/lucas-ropek/)
