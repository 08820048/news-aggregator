---
title: "Attacking machine learning with adversarial examples"
source: "Unknown"
url: "https://openai.com/index/attacking-machine-learning-with-adversarial-examples"
published: "2017-02-24T08:00:00.000Z"
category: "ai"
summary: "Adversarial examples are inputs to machine learning models that an attacker has intentionally designed to cause the model to make a mistake; they’re like optical illusions for machines. In this post we’ll show how adversarial examples work across different mediums, and will discuss why securing systems against them can be difficult."
---
Adversarial examples are inputs to machine learning models that an attacker has intentionally designed to cause the model to make a mistake; they’re like optical illusions for machines. In this post we’ll show how adversarial examples work across different mediums, and will discuss why securing systems against them can be difficult.
